{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install Dependencies and Bring in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenchalla/anaconda3/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jigsaw-toxic-comment-classification-challenge/train.csv/train.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['toxic']==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenchalla/anaconda3/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- --------------------\n",
      "absl-py                       2.0.0\n",
      "aiobotocore                   2.5.0\n",
      "aiofiles                      22.1.0\n",
      "aiohttp                       3.8.3\n",
      "aioitertools                  0.7.1\n",
      "aiosignal                     1.2.0\n",
      "aiosqlite                     0.18.0\n",
      "alabaster                     0.7.12\n",
      "altair                        5.3.0\n",
      "anaconda-catalogs             0.2.0\n",
      "anaconda-client               1.11.3\n",
      "anaconda-navigator            2.4.2\n",
      "anaconda-project              0.11.1\n",
      "annotated-types               0.6.0\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "applaunchservices             0.3.0\n",
      "appnope                       0.1.2\n",
      "appscript                     1.1.2\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.3\n",
      "astroid                       2.14.2\n",
      "astropy                       5.1\n",
      "asttokens                     2.0.5\n",
      "astunparse                    1.6.3\n",
      "async-timeout                 4.0.2\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         22.1.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.11.0\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.12.2\n",
      "binaryornot                   0.4.4\n",
      "black                         0.0\n",
      "bleach                        4.1.0\n",
      "bokeh                         3.1.1\n",
      "boltons                       23.0.0\n",
      "botocore                      1.29.76\n",
      "Bottleneck                    1.3.5\n",
      "brotlipy                      0.7.0\n",
      "cachetools                    5.3.2\n",
      "certifi                       2024.2.2\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.2.1\n",
      "clyent                        1.2.2\n",
      "colorama                      0.4.6\n",
      "colorcet                      3.0.1\n",
      "comm                          0.1.2\n",
      "conda                         23.7.4\n",
      "conda-build                   3.25.0\n",
      "conda-content-trust           0.1.3\n",
      "conda_index                   0.2.3\n",
      "conda-libmamba-solver         23.5.0\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        2.1.0\n",
      "conda_package_streaming       0.8.0\n",
      "conda-repo-cli                1.0.41\n",
      "conda-token                   0.4.0\n",
      "conda-verify                  3.4.2\n",
      "constantly                    15.1.0\n",
      "contourpy                     1.0.5\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  39.0.1\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "cytoolz                       0.12.0\n",
      "dask                          2023.6.0\n",
      "datasets                      2.12.0\n",
      "datashader                    0.15.0\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.6\n",
      "distributed                   2023.6.0\n",
      "docstring-to-markdown         0.11\n",
      "docutils                      0.18.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     0.8.3\n",
      "fastapi                       0.110.2\n",
      "fastjsonschema                2.16.2\n",
      "ffmpy                         0.3.2\n",
      "filelock                      3.9.0\n",
      "flake8                        6.0.0\n",
      "Flask                         2.2.2\n",
      "flatbuffers                   23.5.26\n",
      "fonttools                     4.25.0\n",
      "frozenlist                    1.3.3\n",
      "fsspec                        2023.6.0\n",
      "future                        0.18.3\n",
      "gast                          0.5.4\n",
      "gensim                        4.3.0\n",
      "gitdb                         4.0.11\n",
      "GitPython                     3.1.41\n",
      "glob2                         0.7\n",
      "gmpy2                         2.1.2\n",
      "google-auth                   2.23.4\n",
      "google-auth-oauthlib          1.1.0\n",
      "google-pasta                  0.2.0\n",
      "gradio                        4.27.0\n",
      "gradio_client                 0.15.1\n",
      "graphviz                      0.20.1\n",
      "greenlet                      2.0.1\n",
      "grpcio                        1.59.3\n",
      "h11                           0.14.0\n",
      "h5py                          3.7.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.16.2\n",
      "httpcore                      1.0.5\n",
      "httpx                         0.27.0\n",
      "huggingface-hub               0.22.2\n",
      "hvplot                        0.8.4\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.4\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.31.1\n",
      "imagesize                     1.4.1\n",
      "imbalanced-learn              0.10.1\n",
      "imblearn                      0.0\n",
      "importlib-metadata            6.0.0\n",
      "importlib_resources           6.4.0\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.8\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.19.2\n",
      "ipython                       8.12.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    8.0.4\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jaraco.classes                3.2.1\n",
      "jax                           0.4.26\n",
      "jaxlib                        0.4.26\n",
      "jedi                          0.18.1\n",
      "jellyfish                     0.9.0\n",
      "Jinja2                        3.1.2\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.2.0\n",
      "json5                         0.9.6\n",
      "jsonpatch                     1.32\n",
      "jsonpointer                   2.1\n",
      "jsonschema                    4.17.3\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.4.9\n",
      "jupyter-console               6.6.3\n",
      "jupyter_core                  5.3.0\n",
      "jupyter-events                0.6.3\n",
      "jupyter-server                1.23.4\n",
      "jupyter_server_fileid         0.9.0\n",
      "jupyter_server_terminals      0.4.4\n",
      "jupyter_server_ydoc           0.8.0\n",
      "jupyter-ydoc                  0.2.4\n",
      "jupyterlab                    3.6.3\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab_server             2.22.0\n",
      "jupyterlab-widgets            3.0.5\n",
      "keras                         2.15.0\n",
      "keyring                       23.13.1\n",
      "kiwisolver                    1.4.4\n",
      "labelImg                      1.8.6\n",
      "lazy_loader                   0.2\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "libclang                      16.0.6\n",
      "libmambapy                    1.4.1\n",
      "linkify-it-py                 2.0.0\n",
      "llvmlite                      0.40.0\n",
      "lmdb                          1.4.1\n",
      "locket                        1.0.0\n",
      "lxml                          5.2.1\n",
      "lxml_html_clean               0.1.1\n",
      "lz4                           4.3.2\n",
      "Markdown                      3.4.1\n",
      "markdown-it-py                2.2.0\n",
      "MarkupSafe                    2.1.1\n",
      "matplotlib                    3.7.1\n",
      "matplotlib-inline             0.1.6\n",
      "mccabe                        0.7.0\n",
      "mdit-py-plugins               0.3.0\n",
      "mdurl                         0.1.0\n",
      "mediapipe                     0.10.11\n",
      "mistune                       0.8.4\n",
      "ml-dtypes                     0.2.0\n",
      "more-itertools                8.12.0\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multidict                     6.0.2\n",
      "multipledispatch              0.6.0\n",
      "multiprocess                  0.70.14\n",
      "munkres                       1.1.4\n",
      "mypy-extensions               0.4.3\n",
      "navigator-updater             0.4.0\n",
      "nbclassic                     0.5.5\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.5.4\n",
      "nbformat                      5.7.0\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      2.8.4\n",
      "nltk                          3.7\n",
      "notebook                      6.5.4\n",
      "notebook_shim                 0.2.2\n",
      "numba                         0.57.0\n",
      "numexpr                       2.8.4\n",
      "numpy                         1.24.3\n",
      "numpydoc                      1.5.0\n",
      "oauthlib                      3.2.2\n",
      "opencv-contrib-python         4.9.0.80\n",
      "opencv-python                 4.9.0.80\n",
      "openpyxl                      3.0.10\n",
      "opt-einsum                    3.3.0\n",
      "orjson                        3.10.1\n",
      "packaging                     23.0\n",
      "pandas                        1.5.3\n",
      "pandocfilters                 1.5.0\n",
      "panel                         1.1.0\n",
      "param                         1.13.0\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathlib                       1.0.1\n",
      "pathspec                      0.10.3\n",
      "patsy                         0.5.3\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           23.1.2\n",
      "pkginfo                       1.9.6\n",
      "platformdirs                  2.5.2\n",
      "plotly                        5.9.0\n",
      "pluggy                        1.0.0\n",
      "ply                           3.11\n",
      "pooch                         1.4.0\n",
      "poyo                          0.5.0\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.36\n",
      "Protego                       0.1.16\n",
      "protobuf                      3.20.3\n",
      "psutil                        5.9.0\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "py-cpuinfo                    8.0.0\n",
      "pyarrow                       11.0.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.10.0\n",
      "pycosat                       0.6.4\n",
      "pycparser                     2.21\n",
      "pyct                          0.5.0\n",
      "pycurl                        7.45.2\n",
      "pydantic                      2.7.0\n",
      "pydantic_core                 2.18.1\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.3.0\n",
      "pydub                         0.25.1\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      3.0.1\n",
      "Pygments                      2.15.1\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.16.2\n",
      "pylint-venv                   2.3.0\n",
      "pyls-spyder                   0.4.0\n",
      "pyobjc-core                   9.0\n",
      "pyobjc-framework-Cocoa        9.0\n",
      "pyobjc-framework-CoreServices 9.0\n",
      "pyobjc-framework-FSEvents     9.0\n",
      "pyodbc                        4.0.34\n",
      "pyOpenSSL                     23.0.0\n",
      "pyparsing                     3.0.9\n",
      "pypng                         0.20220715.0\n",
      "PyQt5                         5.15.10\n",
      "PyQt5-Qt5                     5.15.13\n",
      "PyQt5-sip                     12.13.0\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.3.1\n",
      "python-dateutil               2.8.2\n",
      "python-json-logger            2.0.7\n",
      "python-lsp-black              1.2.1\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.7.2\n",
      "python-multipart              0.0.9\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.1\n",
      "pytoolconfig                  1.2.5\n",
      "pytz                          2022.7\n",
      "pyviz-comms                   2.3.0\n",
      "PyWavelets                    1.4.1\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "QDarkStyle                    3.0.2\n",
      "qrcode                        7.4.2\n",
      "qstylizer                     0.2.2\n",
      "QtAwesome                     1.2.2\n",
      "qtconsole                     5.4.2\n",
      "QtPy                          2.2.0\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.7.9\n",
      "requests                      2.31.0\n",
      "requests-file                 1.5.1\n",
      "requests-oauthlib             1.3.1\n",
      "requests-toolbelt             0.9.1\n",
      "responses                     0.13.3\n",
      "rfc3339-validator             0.1.4\n",
      "rfc3986-validator             0.1.1\n",
      "rich                          13.7.1\n",
      "rope                          1.7.0\n",
      "rsa                           4.9\n",
      "Rtree                         1.0.1\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel-yaml-conda             0.17.21\n",
      "ruff                          0.4.1\n",
      "s3fs                          2023.6.0\n",
      "sacremoses                    0.0.43\n",
      "scikit-image                  0.20.0\n",
      "scikit-learn                  1.2.2\n",
      "scipy                         1.10.1\n",
      "Scrapy                        2.8.0\n",
      "seaborn                       0.12.2\n",
      "semantic-version              2.10.0\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    67.8.0\n",
      "shellingham                   1.5.4\n",
      "sip                           6.6.2\n",
      "six                           1.16.0\n",
      "sklearn                       0.0.post9\n",
      "smart-open                    5.2.1\n",
      "smmap                         5.0.1\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "sounddevice                   0.4.6\n",
      "soupsieve                     2.4\n",
      "Sphinx                        5.0.2\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.4.3\n",
      "spyder-kernels                2.4.3\n",
      "SQLAlchemy                    1.4.39\n",
      "stack-data                    0.2.0\n",
      "starlette                     0.37.2\n",
      "statsmodels                   0.13.5\n",
      "sympy                         1.11.1\n",
      "tables                        3.8.0\n",
      "tabulate                      0.8.10\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.2\n",
      "tensorboard                   2.15.1\n",
      "tensorboard-data-server       0.7.2\n",
      "tensorflow                    2.15.0\n",
      "tensorflow-estimator          2.15.0\n",
      "tensorflow-io-gcs-filesystem  0.34.0\n",
      "tensorflow-macos              2.15.0\n",
      "termcolor                     2.3.0\n",
      "terminado                     0.17.1\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "thop                          0.1.1.post2209072238\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss2                      1.2.1\n",
      "tldextract                    3.2.0\n",
      "tokenizers                    0.13.2\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "tomlkit                       0.12.0\n",
      "toolz                         0.12.0\n",
      "torch                         2.2.2\n",
      "torchaudio                    2.2.2\n",
      "torchvision                   0.17.2\n",
      "tornado                       6.2\n",
      "tqdm                          4.65.0\n",
      "traitlets                     5.7.1\n",
      "transformers                  4.29.2\n",
      "Twisted                       22.10.0\n",
      "typer                         0.12.3\n",
      "typing_extensions             4.11.0\n",
      "uc-micro-py                   1.0.1\n",
      "ujson                         5.4.0\n",
      "ultralytics                   8.1.44\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       2.2.1\n",
      "uvicorn                       0.29.0\n",
      "w3lib                         1.21.0\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "websockets                    11.0.3\n",
      "Werkzeug                      2.2.3\n",
      "whatthepatch                  1.0.2\n",
      "wheel                         0.38.4\n",
      "widgetsnbextension            4.0.5\n",
      "wrapt                         1.14.1\n",
      "wurlitzer                     3.0.2\n",
      "xarray                        2022.11.0\n",
      "xlwings                       0.29.1\n",
      "xxhash                        2.0.2\n",
      "xyzservices                   2022.9.0\n",
      "y-py                          0.5.9\n",
      "yapf                          0.31.0\n",
      "yarl                          1.8.1\n",
      "ypy-websocket                 0.8.2\n",
      "zict                          2.2.0\n",
      "zipp                          3.11.0\n",
      "zope.interface                5.4.0\n",
      "zstandard                     0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "#tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextVectorization in module keras.src.layers.preprocessing.text_vectorization:\n",
      "\n",
      "class TextVectorization(keras.src.engine.base_preprocessing_layer.PreprocessingLayer)\n",
      " |  TextVectorization(max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, idf_weights=None, sparse=False, ragged=False, encoding='utf-8', **kwargs)\n",
      " |  \n",
      " |  A preprocessing layer which maps text features to integer sequences.\n",
      " |  \n",
      " |  This layer has basic options for managing text in a Keras model. It\n",
      " |  transforms a batch of strings (one example = one string) into either a list\n",
      " |  of token indices (one example = 1D tensor of integer token indices) or a\n",
      " |  dense representation (one example = 1D tensor of float values representing\n",
      " |  data about the example's tokens). This layer is meant to handle natural\n",
      " |  language inputs. To handle simple string inputs (categorical strings or\n",
      " |  pre-tokenized strings) see `tf.keras.layers.StringLookup`.\n",
      " |  \n",
      " |  The vocabulary for the layer must be either supplied on construction or\n",
      " |  learned via `adapt()`. When this layer is adapted, it will analyze the\n",
      " |  dataset, determine the frequency of individual string values, and create a\n",
      " |  vocabulary from them. This vocabulary can have unlimited size or be capped,\n",
      " |  depending on the configuration options for this layer; if there are more\n",
      " |  unique values in the input than the maximum vocabulary size, the most\n",
      " |  frequent terms will be used to create the vocabulary.\n",
      " |  \n",
      " |  The processing of each example contains the following steps:\n",
      " |  \n",
      " |  1. Standardize each example (usually lowercasing + punctuation stripping)\n",
      " |  2. Split each example into substrings (usually words)\n",
      " |  3. Recombine substrings into tokens (usually ngrams)\n",
      " |  4. Index tokens (associate a unique int value with each token)\n",
      " |  5. Transform each example using this index, either into a vector of ints or\n",
      " |     a dense float vector.\n",
      " |  \n",
      " |  Some notes on passing callables to customize splitting and normalization for\n",
      " |  this layer:\n",
      " |  \n",
      " |  1. Any callable can be passed to this Layer, but if you want to serialize\n",
      " |     this object you should only pass functions that are registered Keras\n",
      " |     serializables (see `tf.keras.saving.register_keras_serializable` for more\n",
      " |     details).\n",
      " |  2. When using a custom callable for `standardize`, the data received\n",
      " |     by the callable will be exactly as passed to this layer. The callable\n",
      " |     should return a tensor of the same shape as the input.\n",
      " |  3. When using a custom callable for `split`, the data received by the\n",
      " |     callable will have the 1st dimension squeezed out - instead of\n",
      " |     `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n",
      " |     see `[\"string to split\", \"another string to split\"]`. The callable should\n",
      " |     return a Tensor with the first dimension containing the split tokens -\n",
      " |     in this example, we should see something like `[[\"string\", \"to\",\n",
      " |     \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n",
      " |     site natively compatible with `tf.strings.split()`.\n",
      " |  \n",
      " |  For an overview and full list of preprocessing layers, see the preprocessing\n",
      " |  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
      " |  \n",
      " |  Args:\n",
      " |    max_tokens: Maximum size of the vocabulary for this layer. This should\n",
      " |      only be specified when adapting a vocabulary or when setting\n",
      " |      `pad_to_max_tokens=True`. Note that this vocabulary\n",
      " |      contains 1 OOV token, so the effective number of tokens is\n",
      " |      `(max_tokens - 1 - (1 if output_mode == \"int\" else 0))`.\n",
      " |    standardize: Optional specification for standardization to apply to the\n",
      " |      input text. Values can be:\n",
      " |        - `None`: No standardization.\n",
      " |        - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all\n",
      " |          punctuation removed.\n",
      " |        - `\"lower\"`: Text will be lowercased.\n",
      " |        - `\"strip_punctuation\"`: All punctuation will be removed.\n",
      " |        - Callable: Inputs will passed to the callable function, which should\n",
      " |          be standardized and returned.\n",
      " |    split: Optional specification for splitting the input text. Values can be:\n",
      " |        - `None`: No splitting.\n",
      " |        - `\"whitespace\"`: Split on whitespace.\n",
      " |        - `\"character\"`: Split on each unicode character.\n",
      " |        - Callable: Standardized inputs will passed to the callable function,\n",
      " |          which should be split and returned.\n",
      " |    ngrams: Optional specification for ngrams to create from the\n",
      " |      possibly-split input text. Values can be None, an integer or tuple of\n",
      " |      integers; passing an integer will create ngrams up to that integer, and\n",
      " |      passing a tuple of integers will create ngrams for the specified values\n",
      " |      in the tuple. Passing None means that no ngrams will be created.\n",
      " |    output_mode: Optional specification for the output of the layer. Values\n",
      " |      can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the\n",
      " |      layer as follows:\n",
      " |        - `\"int\"`: Outputs integer indices, one integer index per split string\n",
      " |          token. When `output_mode == \"int\"`, 0 is reserved for masked\n",
      " |          locations; this reduces the vocab size to\n",
      " |          `max_tokens - 2` instead of `max_tokens - 1`.\n",
      " |        - `\"multi_hot\"`: Outputs a single int array per batch, of either\n",
      " |          vocab_size or max_tokens size, containing 1s in all elements where\n",
      " |          the token mapped to that index exists at least once in the batch\n",
      " |          item.\n",
      " |        - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\n",
      " |          the number of times the token at that index appeared in the\n",
      " |          batch item.\n",
      " |        - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied\n",
      " |          to find the value in each token slot.\n",
      " |      For `\"int\"` output, any shape of input and output is supported. For all\n",
      " |      other output modes, currently only rank 1 inputs (and rank 2 outputs\n",
      " |      after splitting) are supported.\n",
      " |    output_sequence_length: Only valid in INT mode. If set, the output will\n",
      " |      have its time dimension padded or truncated to exactly\n",
      " |      `output_sequence_length` values, resulting in a tensor of shape\n",
      " |      `(batch_size, output_sequence_length)` regardless of how many tokens\n",
      " |      resulted from the splitting step. Defaults to `None`.\n",
      " |    pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\n",
      " |      modes. If True, the output will have its feature axis padded to\n",
      " |      `max_tokens` even if the number of unique tokens in the vocabulary is\n",
      " |      less than max_tokens, resulting in a tensor of shape `(batch_size,\n",
      " |      max_tokens)` regardless of vocabulary size. Defaults to `False`.\n",
      " |    vocabulary: Optional. Either an array of strings or a string path to a\n",
      " |      text file. If passing an array, can pass a tuple, list, 1D numpy array,\n",
      " |      or 1D tensor containing the string vocabulary terms. If passing a file\n",
      " |      path, the file should contain one line per term in the vocabulary. If\n",
      " |      this argument is set, there is no need to `adapt()` the layer.\n",
      " |    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list,\n",
      " |      1D numpy array, or 1D tensor of the same length as the vocabulary,\n",
      " |      containing the floating point inverse document frequency weights, which\n",
      " |      will be multiplied by per sample term counts for the final `tf_idf`\n",
      " |      weight. If the `vocabulary` argument is set, and `output_mode` is\n",
      " |      `\"tf_idf\"`, this argument must be supplied.\n",
      " |    ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns\n",
      " |      a `RaggedTensor` instead of a dense `Tensor`, where each sequence may\n",
      " |      have a different length after string splitting. Defaults to `False`.\n",
      " |    sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n",
      " |      `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n",
      " |      dense `Tensor`. Defaults to `False`.\n",
      " |    encoding: Optional. The text encoding to use to interpret the input\n",
      " |      strings. Defaults to `\"utf-8\"`.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  This example instantiates a `TextVectorization` layer that lowercases text,\n",
      " |  splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
      " |  \n",
      " |  >>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
      " |  >>> max_features = 5000  # Maximum vocab size.\n",
      " |  >>> max_len = 4  # Sequence length to pad the outputs to.\n",
      " |  >>>\n",
      " |  >>> # Create the layer.\n",
      " |  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
      " |  ...  max_tokens=max_features,\n",
      " |  ...  output_mode='int',\n",
      " |  ...  output_sequence_length=max_len)\n",
      " |  >>>\n",
      " |  >>> # Now that the vocab layer has been created, call `adapt` on the\n",
      " |  >>> # text-only dataset to create the vocabulary. You don't have to batch,\n",
      " |  >>> # but for large datasets this means we're not keeping spare copies of\n",
      " |  >>> # the dataset.\n",
      " |  >>> vectorize_layer.adapt(text_dataset.batch(64))\n",
      " |  >>>\n",
      " |  >>> # Create the model that uses the vectorize text layer\n",
      " |  >>> model = tf.keras.models.Sequential()\n",
      " |  >>>\n",
      " |  >>> # Start by creating an explicit input layer. It needs to have a shape of\n",
      " |  >>> # (1,) (because we need to guarantee that there is exactly one string\n",
      " |  >>> # input per batch), and the dtype needs to be 'string'.\n",
      " |  >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
      " |  >>>\n",
      " |  >>> # The first layer in our model is the vectorization layer. After this\n",
      " |  >>> # layer, we have a tensor of shape (batch_size, max_len) containing\n",
      " |  >>> # vocab indices.\n",
      " |  >>> model.add(vectorize_layer)\n",
      " |  >>>\n",
      " |  >>> # Now, the model can map strings to integers, and you can add an\n",
      " |  >>> # embedding layer to map these integers to learned embeddings.\n",
      " |  >>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
      " |  >>> model.predict(input_data)\n",
      " |  array([[2, 1, 4, 0],\n",
      " |         [1, 3, 0, 0]])\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  This example instantiates a `TextVectorization` layer by passing a list\n",
      " |  of vocabulary terms to the layer's `__init__()` method.\n",
      " |  \n",
      " |  >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n",
      " |  >>> max_len = 4  # Sequence length to pad the outputs to.\n",
      " |  >>>\n",
      " |  >>> # Create the layer, passing the vocab directly. You can also pass the\n",
      " |  >>> # vocabulary arg a path to a file containing one vocabulary word per\n",
      " |  >>> # line.\n",
      " |  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
      " |  ...  max_tokens=max_features,\n",
      " |  ...  output_mode='int',\n",
      " |  ...  output_sequence_length=max_len,\n",
      " |  ...  vocabulary=vocab_data)\n",
      " |  >>>\n",
      " |  >>> # Because we've passed the vocabulary directly, we don't need to adapt\n",
      " |  >>> # the layer - the vocabulary is already set. The vocabulary contains the\n",
      " |  >>> # padding token ('') and OOV token ('[UNK]') as well as the passed\n",
      " |  >>> # tokens.\n",
      " |  >>> vectorize_layer.get_vocabulary()\n",
      " |  ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextVectorization\n",
      " |      keras.src.engine.base_preprocessing_layer.PreprocessingLayer\n",
      " |      keras.src.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.src.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, idf_weights=None, sparse=False, ragged=False, encoding='utf-8', **kwargs)\n",
      " |  \n",
      " |  adapt(self, data, batch_size=None, steps=None)\n",
      " |      Computes a vocabulary of string terms from tokens in a dataset.\n",
      " |      \n",
      " |      Calling `adapt()` on a `TextVectorization` layer is an alternative to\n",
      " |      passing in a precomputed vocabulary on construction via the `vocabulary`\n",
      " |      argument. A `TextVectorization` layer should always be either adapted\n",
      " |      over a dataset or supplied with a vocabulary.\n",
      " |      \n",
      " |      During `adapt()`, the layer will build a vocabulary of all string tokens\n",
      " |      seen in the dataset, sorted by occurrence count, with ties broken by\n",
      " |      sort order of the tokens (high to low). At the end of `adapt()`, if\n",
      " |      `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`\n",
      " |      size. For example, adapting a layer with `max_tokens=1000` will compute\n",
      " |      the 1000 most frequent tokens occurring in the input dataset. If\n",
      " |      `output_mode='tf-idf'`, `adapt()` will also learn the document\n",
      " |      frequencies of each token in the input dataset.\n",
      " |      \n",
      " |      In order to make `TextVectorization` efficient in any distribution\n",
      " |      context, the vocabulary is kept static with respect to any compiled\n",
      " |      `tf.Graph`s that call the layer. As a consequence, if the layer is\n",
      " |      adapted a second time, any models using the layer should be re-compiled.\n",
      " |      For more information see\n",
      " |      `tf.keras.layers.experimental.preprocessing.PreprocessingLayer.adapt`.\n",
      " |      \n",
      " |      `adapt()` is meant only as a single machine utility to compute layer\n",
      " |      state.  To analyze a dataset that cannot fit on a single machine, see\n",
      " |      [Tensorflow Transform](\n",
      " |      https://www.tensorflow.org/tfx/transform/get_started) for a\n",
      " |      multi-machine, map-reduce solution.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: The data to train on. It can be passed either as a\n",
      " |            `tf.data.Dataset`, or as a numpy array.\n",
      " |        batch_size: Integer or `None`.\n",
      " |            Number of samples per state update.\n",
      " |            If unspecified, `batch_size` will default to 32.\n",
      " |            Do not specify the `batch_size` if your data is in the\n",
      " |            form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |            (since they generate batches).\n",
      " |        steps: Integer or `None`.\n",
      " |            Total number of steps (batches of samples)\n",
      " |            When training with input tensors such as\n",
      " |            TensorFlow data tensors, the default `None` is equal to\n",
      " |            the number of samples in your dataset divided by\n",
      " |            the batch size, or 1 if that cannot be determined. If x is a\n",
      " |            `tf.data` dataset, and 'steps' is None, the epoch will run until\n",
      " |            the input dataset is exhausted. When passing an infinitely\n",
      " |            repeating dataset, you must specify the `steps` argument. This\n",
      " |            argument is not supported with array inputs.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      The `call()` method may not create state (except in its first\n",
      " |      invocation, wrapping the creation of variables or other resources in\n",
      " |      `tf.init_scope()`).  It is recommended to create state, including\n",
      " |      `tf.Variable` instances and nested `Layer` instances,\n",
      " |       in `__init__()`, or in the `build()` method that is\n",
      " |      called automatically before `call()` executes for the first time.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as\n",
      " |            tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs`\n",
      " |            only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask\n",
      " |            generated for `inputs` by the previous layer (if `input` did come\n",
      " |            from a layer that generated a corresponding mask, i.e. if it came\n",
      " |            from a Keras layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
      " |              or structure of shape tuples / `tf.TensorShape` instances\n",
      " |              (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `tf.TensorShape` instance\n",
      " |          or structure of `tf.TensorShape` instances.\n",
      " |  \n",
      " |  compute_output_signature(self, input_spec)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalize the statistics for the preprocessing layer.\n",
      " |      \n",
      " |      This method is called at the end of `adapt` or after restoring a\n",
      " |      serialized preprocessing layer's state. This method handles any one-time\n",
      " |      operations that should occur on the layer's state before\n",
      " |      `Layer.__call__`.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_vocabulary(self, include_special_tokens=True)\n",
      " |      Returns the current vocabulary of the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        include_special_tokens: If True, the returned vocabulary will include\n",
      " |          the padding and OOV tokens, and a term's index in the vocabulary\n",
      " |          will equal the term's index when calling the layer. If False, the\n",
      " |          returned vocabulary will not include any padding or OOV tokens.\n",
      " |  \n",
      " |  load_assets(self, dir_path)\n",
      " |  \n",
      " |  load_own_variables(self, store)\n",
      " |      Loads the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict from which the state of the model will be loaded.\n",
      " |  \n",
      " |  reset_state(self)\n",
      " |      Resets the statistics of the preprocessing layer.\n",
      " |  \n",
      " |  save_assets(self, dir_path)\n",
      " |  \n",
      " |  save_own_variables(self, store)\n",
      " |      Saves the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is saved upon calling `model.save()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict where the state of the model will be saved.\n",
      " |  \n",
      " |  set_vocabulary(self, vocabulary, idf_weights=None)\n",
      " |      Sets vocabulary (and optionally document frequency) for this layer.\n",
      " |      \n",
      " |      This method sets the vocabulary and idf weights for this layer directly,\n",
      " |      instead of analyzing a dataset through 'adapt'. It should be used\n",
      " |      whenever the vocab (and optionally document frequency) information is\n",
      " |      already known.  If vocabulary data is already present in the layer, this\n",
      " |      method will replace it.\n",
      " |      \n",
      " |      Args:\n",
      " |        vocabulary: Either an array or a string path to a text file. If\n",
      " |          passing an array, can pass a tuple, list, 1D numpy array, or 1D\n",
      " |          tensor containing the vocbulary terms. If passing a file path, the\n",
      " |          file should contain one line per term in the vocabulary.\n",
      " |        idf_weights: A tuple, list, 1D numpy array, or 1D tensor of inverse\n",
      " |          document frequency weights with equal length to vocabulary. Must be\n",
      " |          set if `output_mode` is `\"tf_idf\"`. Should not be set otherwise.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If there are too many inputs, the inputs do not match, or\n",
      " |          input data is missing.\n",
      " |        RuntimeError: If the vocabulary cannot be set when this function is\n",
      " |          called. This happens when `\"multi_hot\"`, `\"count\"`, and \"tf_idf\"\n",
      " |          modes, if `pad_to_max_tokens` is False and the layer itself has\n",
      " |          already been called.\n",
      " |  \n",
      " |  update_state(self, data)\n",
      " |      Accumulates statistics for the preprocessing layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A mini-batch of inputs to the layer.\n",
      " |  \n",
      " |  vocabulary_size(self)\n",
      " |      Gets the current size of the layer's vocabulary.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The integer size of the vocabulary, including optional mask and\n",
      " |        OOV indices.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config) from abc.ABCMeta\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.engine.base_preprocessing_layer.PreprocessingLayer:\n",
      " |  \n",
      " |  compile(self, run_eagerly=None, steps_per_execution=None)\n",
      " |      Configures the layer for `adapt`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        run_eagerly: Bool. If `True`, this `Model`'s\n",
      " |          logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |          this as `None` unless your `Model` cannot be run inside a\n",
      " |          `tf.function`. Defaults to `False`.\n",
      " |        steps_per_execution: Int. The number of batches to run\n",
      " |          during each `tf.function` call. Running multiple batches inside a\n",
      " |          single `tf.function` call can greatly improve performance on TPUs or\n",
      " |          small models with a large Python overhead. Defaults to `1`.\n",
      " |  \n",
      " |  make_adapt_function(self)\n",
      " |      Creates a function to execute one step of `adapt`.\n",
      " |      \n",
      " |      This method can be overridden to support custom adapt logic.\n",
      " |      This method is called by `PreprocessingLayer.adapt`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` settings,\n",
      " |      and delegates the actual state update logic to\n",
      " |      `PreprocessingLayer.update_state`.\n",
      " |      \n",
      " |      This function is cached the first time `PreprocessingLayer.adapt`\n",
      " |      is called. The cache is cleared whenever `PreprocessingLayer.compile`\n",
      " |      is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, retrieve a batch, and update the state of the\n",
      " |        layer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.engine.base_preprocessing_layer.PreprocessingLayer:\n",
      " |  \n",
      " |  is_adapted\n",
      " |      Whether the layer has been fit to data already.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific\n",
      " |          uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid\n",
      " |          value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the\n",
      " |          constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      The same code works in distributed training: the input to `add_loss()`\n",
      " |      is treated like a regularization loss and averaged across replicas\n",
      " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
      " |      training loops).\n",
      " |      \n",
      " |      The `add_loss` method can also be called directly on a Functional Model\n",
      " |      during construction. In this case, any loss Tensors passed to this Model\n",
      " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
      " |      These losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |           for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  build_from_config(self, config)\n",
      " |      Builds the layer's states with the supplied config dict.\n",
      " |      \n",
      " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
      " |      which creates weights based on the layer's input shape in the supplied\n",
      " |      config. If your config contains other information needed to load the\n",
      " |      layer's state, you should override this method.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Dict containing the input shape associated with this layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_build_config(self)\n",
      " |      Returns a dictionary with the layer's input shape.\n",
      " |      \n",
      " |      This method returns a config dict that can be used by\n",
      " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
      " |      Lookup tables) needed by the layer.\n",
      " |      \n",
      " |      By default, the config only contains the input shape that the layer\n",
      " |      was built with. If you're writing a custom layer that creates state in\n",
      " |      an unusual way, you should override this method to make sure this state\n",
      " |      is already created when Keras attempts to load its value upon model\n",
      " |      loading.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict containing the input shape associated with the layer.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics attached to the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.src.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from abc.ABCMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextVectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Explanation\\nWhy the edits made under my usern...\n",
      "1         D'aww! He matches this background colour I'm s...\n",
      "2         Hey man, I'm really not trying to edit war. It...\n",
      "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
      "4         You, sir, are my hero. Any chance you remember...\n",
      "                                ...                        \n",
      "159566    \":::::And for the second time of asking, when ...\n",
      "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
      "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
      "159569    And it looks like it was actually you who put ...\n",
      "159570    \"\\nAnd ... I really don't think you understand...\n",
      "Name: comment_text, Length: 159571, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 # number of words in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([288, 263, 306,   9, 275])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer('Hello world, life is great')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
    "#datapipelines\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1304,     3,    36, ...,     0,     0,     0],\n",
       "        [ 1442,  7843, 22749, ...,     0,     0,     0],\n",
       "        [ 1761,    11, 18694, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 1757,     7,    20, ...,     0,     0,     0],\n",
       "        [ 2093,  1040,    12, ...,     0,     0,     0],\n",
       "        [   16,  3534,   200, ...,     0,     0,     0]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X,batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6981"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(dataset)*.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1869,  1421,     8, ...,     0,     0,     0],\n",
       "        [  124,     7,    13, ...,     0,     0,     0],\n",
       "        [   46,  3884,    29, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    8,    74,  3435, ...,     0,     0,     0],\n",
       "        [ 2023,     2, 14695, ...,     0,     0,     0],\n",
       "        [ 5520,   797,     8, ...,     0,     0,     0]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Create the embedding layer \n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "# Bidirectional LSTM Layer\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "# Feature extractor Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Final layer \n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                16640     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6491686 (24.76 MB)\n",
      "Trainable params: 6491686 (24.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6981/6981 [==============================] - 2753s 394ms/step - loss: 0.0630 - val_loss: 0.0467\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=1, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = vectorizer('You freaking suck! I am going to fuck you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()\n",
    "#give the next batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1800,), dtype=int64, numpy=array([   7, 7158,  397, ...,    0,    0,    0])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7, 7158,  397, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(input_text,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 416ms/step\n",
      "[[0.99796396 0.355217   0.97881615 0.04819175 0.91184294 0.1894193 ]]\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_text,0))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.86845868e-03, 3.49850438e-07, 3.72050417e-04, 5.22093360e-05,\n",
       "       3.36034049e-04, 5.75947779e-05, 1.37837250e-02, 6.88365105e-07,\n",
       "       9.57621902e-04, 9.10197341e-05, 8.10570375e-04, 1.38818548e-04,\n",
       "       2.81976489e-03, 2.10542250e-08, 7.92643987e-05, 9.09751634e-06,\n",
       "       7.01120589e-05, 1.00769776e-05, 4.13023052e-04, 1.89468760e-10,\n",
       "       2.19567155e-05, 6.08911080e-07, 1.17300951e-05, 1.50536709e-06,\n",
       "       2.14057905e-03, 1.10973568e-08, 5.15083375e-05, 6.03632134e-06,\n",
       "       4.57302704e-05, 6.32169667e-06, 4.91614593e-03, 1.01139221e-07,\n",
       "       2.21643873e-04, 2.48203069e-05, 1.84208955e-04, 3.14447025e-05,\n",
       "       4.59423661e-03, 5.67601646e-08, 4.44223260e-04, 2.29620146e-05,\n",
       "       2.93096644e-04, 4.79206974e-05, 5.12648840e-03, 7.14347621e-08,\n",
       "       5.10233338e-04, 2.81077300e-05, 3.38131736e-04, 5.63424401e-05,\n",
       "       1.34102535e-03, 3.58988173e-09, 2.89732925e-05, 2.93040807e-06,\n",
       "       2.42906026e-05, 3.15077182e-06, 1.56586677e-01, 2.86875700e-04,\n",
       "       1.88588090e-02, 4.02338570e-03, 2.13673115e-02, 4.21726145e-03,\n",
       "       9.97855127e-01, 3.55634660e-01, 9.77943659e-01, 4.97121550e-02,\n",
       "       9.10820246e-01, 1.90387174e-01, 3.66028328e-03, 4.29512710e-08,\n",
       "       1.13927003e-04, 1.42820845e-05, 1.00640085e-04, 1.55063808e-05,\n",
       "       3.71896592e-03, 4.46582504e-08, 1.11775058e-04, 1.42463487e-05,\n",
       "       9.92189453e-05, 1.53187702e-05, 5.12663694e-03, 1.02109546e-07,\n",
       "       1.87469836e-04, 2.44175753e-05, 1.64667872e-04, 2.71943281e-05,\n",
       "       4.16218070e-03, 5.73342369e-08, 1.13983944e-04, 1.63558852e-05,\n",
       "       1.04281324e-04, 1.59842621e-05, 4.69146529e-03, 8.21596160e-08,\n",
       "       2.51953374e-04, 2.13344101e-05, 2.03966541e-04, 3.44671716e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    # Unpack the batch \n",
    "    X_true, y_true = batch\n",
    "    # Make a prediction \n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8275862336158752, Recall:0.6886075735092163, Accuracy:0.5175526738166809\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (4.27.0)\n",
      "Requirement already satisfied: jinja2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.110.2)\n",
      "Requirement already satisfied: ffmpy in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.15.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.22.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy~=1.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (3.10.1)\n",
      "Requirement already satisfied: packaging in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (23.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (2.7.0)\n",
      "Requirement already satisfied: pydub in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.4.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: fsspec in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio-client==0.15.1->gradio) (2023.6.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: anyio in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (3.9.0)\n",
      "Requirement already satisfied: requests in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (2.18.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions==3.10.0.2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (3.10.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install typing-extensions==3.10.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: fastapi in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (0.110.2)\n",
      "Requirement already satisfied: gradio in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (4.27.0)\n",
      "Requirement already satisfied: gradio-client in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pydantic) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pydantic) (4.11.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from fastapi) (0.37.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: ffmpy in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.22.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy~=1.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (3.10.1)\n",
      "Requirement already satisfied: packaging in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (23.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydub in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.4.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: urllib3~=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: fsspec in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio-client) (2023.6.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from gradio-client) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: anyio in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (3.9.0)\n",
      "Requirement already satisfied: requests in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pydantic fastapi gradio gradio-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m639.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from torch==2.2.2) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.2.2) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.2.2) (1.2.1)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0.post100\n",
      "    Uninstalling torch-2.1.0.post100:\n",
      "      Successfully uninstalled torch-2.1.0.post100\n",
      "Successfully installed torch-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch==2.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenchalla/anaconda3/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (3.10.0.2)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "Successfully installed typing-extensions-4.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade typing-extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastapi                       0.110.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep fastapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (0.110.2)\n",
      "Requirement already satisfied: typing_extensions in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (4.11.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from fastapi) (2.7.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from fastapi) (0.37.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/praveenchalla/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade fastapi typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenchalla/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_str = vectorizer('hey i freaken hate you! i\\'m gonna hurt you')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 371ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_str,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87950826, 0.07883841, 0.64299345, 0.05641285, 0.5141907 ,\n",
       "        0.10978534]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score_comment, \n",
    "                         inputs=gr.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://1b22e1e475efa97202.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1b22e1e475efa97202.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n"
     ]
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
